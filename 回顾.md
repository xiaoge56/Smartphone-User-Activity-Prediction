测试用的数据都已经是normalization好的，从数值的区间属于（-1，1）可以看出来。
这里用了两种分类方法，一类是决策树，另一种是SVM。
使用起来也很方便，
对于决策树

from sklearn import tree
clf = tree.DecisionTreeClassifier()
clf.fit(train,labels)

对于 svm
from sklearn import svm

clf = svm.SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,
gamma=0.0, kernel='rbf', max_iter=-1, probability=False, random_state=None,
shrinking=True, tol=0.001, verbose=False)
clf = clf.fit(train, labels)

两种方式得到的结果，svm的稍微好于决策树，在把结果提交上去后，得到的是0.89211分数，比决策树高了0.06528.
接着又用了随机森林，但是效果反而下降了一些。
觉得尝试下特征降维和交叉验证的方法看看能否提高效果。

接着我又尝试了下，svm.leanrSVC
测试样本我只抽取了其中的60%作为训练样本，为了防止过拟合
得到了效果又提高了0.02267，结果分数为0.91478。
从排行榜的一行提示可以看到：提交结果用到的预测数据只占到整个提交数据的30%，也就是说，你提交了100个预测结果，目前的排行榜用到了其中的30个结果作为当前排行的依据，而最终的结果是要以100个预测数据的结果作为最终的依据，那么这里面的差距肯定会有变动。

原数据有561个feature，用PCA降为后预测，发现得到的效果反而降低了，说明在降维


